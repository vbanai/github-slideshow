{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pyt/tfseq (0,1) multilabel_sigm_horse_dolphin.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN+WS5bO7j7lO4mjqG+LJrq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vbanai/github-slideshow/blob/master/Pyt_tfseq_(0%2C1)_multilabel_sigm_horse_dolphin.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwswc1wRFVsl"
      },
      "source": [
        "--------------PYTORCH MODELS---------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_rFXed6RUr5"
      },
      "source": [
        "# -------------   HORSE/DOLPHIN EXECRCISE WITH SIGMOID FUNCTION (MULTILABEL)----------------\n",
        "#-----------------FIRST APPROACH WITH NORMAL CONV2D ARCHITECTURE----------------\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "import tarfile\n",
        "from torchvision.datasets.utils import download_url\n",
        "from torch.utils.data import random_split\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "import cv2\n",
        "from torchvision.datasets import MNIST\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split\n",
        "import torch.nn as nn\n",
        "from PIL import Image\n",
        "from torchvision.transforms import ToTensor\n",
        "import numpy as np\n",
        "from torchvision.datasets import ImageFolder\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69QPSJc0At7Q"
      },
      "source": [
        "\n",
        "#stats = ((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "#train_tfms = transforms.Compose([transforms.RandomCrop(32, padding=4, padding_mode='reflect'),\n",
        " #                        transforms.Resize((128, 128)),\n",
        "  #                       transforms.RandomHorizontalFlip(), \n",
        "                         # tt.RandomRotate\n",
        "                         # tt.RandomResizedCrop(256, scale=(0.5,0.9), ratio=(1, 1)), \n",
        "                         # tt.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
        "   #                      transforms.ToTensor(), \n",
        "    #                     transforms.Normalize(*stats,inplace=True)])\n",
        "\n",
        "#ds=ImageFolder(\"/content/horse\", train_tfms)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PjvYA_EBVpt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2dbb2c8-da75-4f3a-c4bc-2944cabc74d5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIOkkdseYFsl"
      },
      "source": [
        "!rm -rf \"/content/train\"\n",
        "!rm -rf \"/content/valid\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVvDJMD4VYRX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "817338a9-5527-4ce3-8756-75094fb23a23"
      },
      "source": [
        "path=\".\"\n",
        "os.chdir(path)\n",
        "os.makedirs(\"train\")\n",
        "os.makedirs(\"valid\")\n",
        "os.makedirs(\"test\")\n",
        "\n",
        "path=\"./train\"\n",
        "os.chdir(path)\n",
        "os.makedirs(\"horse\")\n",
        "os.makedirs(\"dolphin\")\n",
        "os.makedirs(\"dolphin_horse\")\n",
        "\n",
        "path=\"/content/valid\"\n",
        "os.chdir(path)\n",
        "os.makedirs(\"horse\")\n",
        "os.makedirs(\"dolphin\")\n",
        "os.makedirs(\"dolphin_horse\")\n",
        "\n",
        "path=\"/content/test\"\n",
        "os.chdir(path)\n",
        "os.makedirs(\"horse\")\n",
        "os.makedirs(\"dolphin\")\n",
        "os.makedirs(\"dolphin_horse\")\n",
        "\n",
        "!pip install pyunpack\n",
        "!pip install patool\n",
        "from pyunpack import Archive\n",
        "Archive('/content/drive/MyDrive/dolphin_train.rar').extractall('/content/train/dolphin/')\n",
        "Archive('/content/drive/MyDrive/horse_train.rar').extractall('/content/train/horse/')\n",
        "Archive(\"/content/drive/MyDrive/dolphin_horse_train.rar\").extractall('/content/train/dolphin_horse/')\n",
        "Archive('/content/drive/MyDrive/horse_valid.rar').extractall('/content/valid/horse/')\n",
        "Archive('/content/drive/MyDrive/dolphin_valid.rar').extractall('/content/valid/dolphin/')\n",
        "Archive('/content/drive/MyDrive/dolphin_horse_valid.rar').extractall('/content/valid/dolphin_horse/')\n",
        "Archive('/content/drive/MyDrive/DolphinTest.rar').extractall('/content/test/dolphin/')\n",
        "Archive('/content/drive/MyDrive/HorseTest.rar').extractall('/content/test/horse/')\n",
        "Archive(\"/content/drive/MyDrive/DolphinHorseTest.rar\").extractall('/content/test/dolphin_horse/')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyunpack\n",
            "  Downloading https://files.pythonhosted.org/packages/83/29/020436b1d8e96e5f26fa282b9c3c13a3b456a36b9ea2edc87c5fed008369/pyunpack-0.2.2-py2.py3-none-any.whl\n",
            "Collecting entrypoint2\n",
            "  Downloading https://files.pythonhosted.org/packages/8a/b0/8ef4b1d8be02448d164c52466530059d7f57218655d21309a0c4236d7454/entrypoint2-0.2.4-py3-none-any.whl\n",
            "Collecting easyprocess\n",
            "  Downloading https://files.pythonhosted.org/packages/48/3c/75573613641c90c6d094059ac28adb748560d99bd27ee6f80cce398f404e/EasyProcess-0.3-py2.py3-none-any.whl\n",
            "Installing collected packages: entrypoint2, easyprocess, pyunpack\n",
            "Successfully installed easyprocess-0.3 entrypoint2-0.2.4 pyunpack-0.2.2\n",
            "Collecting patool\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/94/52243ddff508780dd2d8110964320ab4851134a55ab102285b46e740f76a/patool-1.12-py2.py3-none-any.whl (77kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 3.5MB/s \n",
            "\u001b[?25hInstalling collected packages: patool\n",
            "Successfully installed patool-1.12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzS5AARfRoHJ"
      },
      "source": [
        "#----------TRAINING DATASET CREATION-------------------------------\n",
        "\n",
        "datadir=\"/content/train/\" \n",
        "train_categories=['horse/horse_train/', 'dolphin/dolphin_train/', 'dolphin_horse/dolphin_horse_train/']\n",
        "\n",
        "dataset_train=[]\n",
        "def create_train_data():\n",
        "  for category in train_categories:\n",
        "    path_train=os.path.join(datadir, category)\n",
        "    if category==\"horse/horse_train/\":\n",
        "      class_num_train=[1,0]\n",
        "    if category==\"dolphin/dolphin_train/\":\n",
        "      class_num_train=[0,1]\n",
        "    if category==\"dolphin_horse/dolphin_horse_train/\":\n",
        "      class_num_train=[1,1]\n",
        "    for img in os.listdir(path_train):  \n",
        "      try:\n",
        "        img_array=cv2.imread(os.path.join(path_train, img))#, cv2.IMREAD_GRAYSCALE)\n",
        "        new_array=cv2.resize(img_array, (64, 64))  \n",
        "        new_array1=new_array/255 \n",
        "        dataset_train.append([new_array1, class_num_train])\n",
        "      except Exception as e:\n",
        "        print(e)\n",
        "\n",
        "create_train_data()\n",
        "\n",
        "import random\n",
        "random.shuffle(dataset_train)\n",
        "\n",
        "inputs_train=[]\n",
        "targets_train=[]\n",
        "\n",
        "for image, label in dataset_train:\n",
        "  inputs_train.append(image)\n",
        "  targets_train.append(label)\n",
        "\n",
        "#---creating np array from the input images\n",
        "arr_inputs_train = np.array(inputs_train)\n",
        "arr_inputs_float_train=arr_inputs_train.astype('float32')\n",
        "\n",
        "\n",
        "#---convert np array of the input images to tensors-----\n",
        "arr_tensor_train = [torch.from_numpy(item).float() for item in arr_inputs_float_train]\n",
        "arr_stack_train=torch.stack(arr_tensor_train)\n",
        "\n",
        "#--- reshape the input images tensor\n",
        "arr_stack_train_reshape=arr_stack_train.reshape(-1,3,64,64) \n",
        "targets_torch_train=torch.tensor(targets_train, dtype=torch.float32)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JvOLA81egui"
      },
      "source": [
        "#----------------VALIDATION DATASET CREATION---------------\n",
        "\n",
        "datadir=\"/content/valid/\" \n",
        "valid_categories=['horse/horse_valid/', 'dolphin/dolphin_valid/', 'dolphin_horse/dolphin_horse_valid/']\n",
        "\n",
        "dataset_valid=[]\n",
        "def create_validation_data():\n",
        "  for category in valid_categories:\n",
        "    path_valid=os.path.join(datadir, category)\n",
        "    if category==\"horse/horse_valid/\":\n",
        "      class_num_valid=[1,0]\n",
        "    if category==\"dolphin/dolphin_valid/\":\n",
        "      class_num_valid=[0,1]\n",
        "    if category==\"dolphin_horse/dolphin_horse_valid/\":\n",
        "      class_num_valid=[1,1]\n",
        "    for img in os.listdir(path_valid):  \n",
        "      try:\n",
        "        img_array=cv2.imread(os.path.join(path_valid, img))#, cv2.IMREAD_GRAYSCALE)\n",
        "        new_array=cv2.resize(img_array, (64, 64))  \n",
        "        new_array1=new_array/255 \n",
        "        dataset_valid.append([new_array1, class_num_valid])\n",
        "      except Exception as e:\n",
        "        print(e)\n",
        "\n",
        "create_validation_data()\n",
        "\n",
        "import random\n",
        "random.shuffle(dataset_valid)\n",
        "\n",
        "inputs_val=[]\n",
        "targets_val=[]\n",
        "\n",
        "for image, label in dataset_valid:\n",
        "  inputs_val.append(image)\n",
        "  targets_val.append(label)\n",
        "\n",
        "#---creating np array from the input images\n",
        "arr_inputs_val = np.array(inputs_val)\n",
        "arr_inputs_float_val=arr_inputs_val.astype('float32')\n",
        "\n",
        "\n",
        "#---convert np array of the input images to tensors-----\n",
        "arr_tensor_val = [torch.from_numpy(item).float() for item in arr_inputs_float_val]\n",
        "arr_stack_val=torch.stack(arr_tensor_val)\n",
        "\n",
        "#--- reshape the input images tensor\n",
        "arr_stack_val_reshape=arr_stack_val.reshape(-1,3,64,64)  #itt vissza 64!!!!!!!!!!!!!!!!!\n",
        "targets_torch_val=torch.tensor(targets_val, dtype=torch.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qexLxMbQqWUj"
      },
      "source": [
        "batch_size=32\n",
        "\n",
        "dataset_tensor_train=TensorDataset(arr_stack_train_reshape, targets_torch_train)\n",
        "dataset_tensor_valid=TensorDataset(arr_stack_val_reshape, targets_torch_val)\n",
        "\n",
        "train_dl = DataLoader(dataset_tensor_train, batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "val_dl = DataLoader(dataset_tensor_valid, batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "\n",
        "#------ END OF CUSTOM DATASET CREATION ---------------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tn19gn3AtMBy"
      },
      "source": [
        "class ImageClassificationBase(nn.Module):\n",
        "  \n",
        "    def training_step(self, batch):\n",
        "        images, labels = batch \n",
        "        out = self(images)                  # Generate predictions\n",
        "        loss = F.binary_cross_entropy(out, labels)  # Calculate loss\n",
        "        return loss\n",
        "    \n",
        "    def validation_step(self, batch):\n",
        "        images, labels = batch\n",
        "        out = self(images)                    # Generate predictions\n",
        "        loss = F.binary_cross_entropy(out, labels)    # Calculate loss\n",
        "        score = F_score(out, labels)\n",
        "        return {'val_loss': loss.detach(), 'val_acc': score}\n",
        "        \n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
        "        batch_accs = [x['val_acc'] for x in outputs]\n",
        "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
        "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
        "    \n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
        "            epoch, result['train_loss'], result['val_loss'], result['val_acc']))\n",
        "        \n",
        "def F_score(output, label, threshold=0.5, beta=1):\n",
        "    prob = output > threshold\n",
        "    label = label > threshold\n",
        "\n",
        "    TP = (prob & label).sum(1).float()\n",
        "    TN = ((~prob) & (~label)).sum(1).float()\n",
        "    FP = (prob & (~label)).sum(1).float()\n",
        "    FN = ((~prob) & label).sum(1).float()\n",
        "\n",
        "    precision = torch.mean(TP / (TP + FP + 1e-12))\n",
        "    recall = torch.mean(TP / (TP + FN + 1e-12))\n",
        "    F2 = (1 + beta**2) * precision * recall / (beta**2 * precision + recall + 1e-12)\n",
        "    return F2.mean(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQx4jSqetNWV"
      },
      "source": [
        "class HorseDolphinCnnModel(ImageClassificationBase):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2), # output: 64 x 32 x 32\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2), # output: 128 x 16 x 16\n",
        "\n",
        "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2), # output: 256 x 8 x 8\n",
        "\n",
        "            nn.MaxPool2d(2, 2), # output: 256 x 4 x 4\n",
        "            \n",
        "            nn.Flatten(), \n",
        "            #nn.Dropout(0.2),\n",
        "            nn.Linear(256*4*4, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 2),\n",
        "            nn.Sigmoid())\n",
        "        \n",
        "    def forward(self, xb):\n",
        "        return self.network(xb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-BqW4JFsZCf"
      },
      "source": [
        "def get_default_device():\n",
        "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "    \n",
        "def to_device(data, device):\n",
        "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
        "    if isinstance(data, (list,tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)\n",
        "\n",
        "class DeviceDataLoader():\n",
        "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "        \n",
        "    def __iter__(self):\n",
        "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
        "        for b in self.dl: \n",
        "            yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Number of batches\"\"\"\n",
        "        return len(self.dl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwS5Xy0rjrGq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgdKVEZZsiFb"
      },
      "source": [
        "device = get_default_device()\n",
        "device"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0DgVBtIuJWb"
      },
      "source": [
        "model = to_device(HorseDolphinCnnModel(), device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMlx9mZAtYhk"
      },
      "source": [
        "def evaluate(model, val_loader):\n",
        "    model.eval()\n",
        "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "    return model.validation_epoch_end(outputs)\n",
        "\n",
        "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
        "    history = []\n",
        "    optimizer = opt_func(model.parameters(), lr)\n",
        "    for epoch in range(epochs):\n",
        "        # Training Phase \n",
        "        model.train()\n",
        "        train_losses = []\n",
        "        for batch in train_loader:\n",
        "            x, y= batch\n",
        "            loss = model.training_step(batch)\n",
        "            train_losses.append(loss)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "        # Validation phase\n",
        "        result = evaluate(model, val_loader)\n",
        "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
        "        model.epoch_end(epoch, result)\n",
        "        history.append(result)\n",
        "    return history\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmbyyD0JswD3"
      },
      "source": [
        "train_dl = DeviceDataLoader(train_dl, device)\n",
        "val_dl = DeviceDataLoader(val_dl, device)\n",
        "#test_dl = DeviceDataLoader(test_dl, device)\n",
        "#to_device(model, device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DG-jY7d3tcTm"
      },
      "source": [
        "num_epochs = 10\n",
        "opt_func = torch.optim.Adam\n",
        "lr = 0.01\n",
        "\n",
        "history = fit(num_epochs, lr, model, train_dl, val_dl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWTJltTyU449"
      },
      "source": [
        "\n",
        "accuracies = [x['val_acc'] for x in history]\n",
        "plt.plot(accuracies)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.title('Accuracy vs. No. of epochs');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CS8naGVTVNA0"
      },
      "source": [
        "\n",
        "train_losses = [x.get('train_loss') for x in history]\n",
        "val_losses = [x['val_loss'] for x in history]\n",
        "plt.plot(train_losses)\n",
        "plt.plot(val_losses)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(['Training', 'Validation'])\n",
        "plt.title('Loss vs. No. of epochs');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l167mbJpzFjq"
      },
      "source": [
        "torch.save(model.state_dict(), 'pics.modelparameters')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJeatELkzlqJ"
      },
      "source": [
        "model2=HorseDolphinCnnModel()\n",
        "model2.load_state_dict(torch.load('pics.modelparameters'))\n",
        "model2.state_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yM64xpNP9Q0x"
      },
      "source": [
        "def predict_image(img, model):\n",
        "    xb = img.unsqueeze(0)\n",
        "    yb = model(xb)\n",
        "    #_, preds  = torch.max(yb, dim=1)\n",
        "    return yb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZS3TR8u5xMT"
      },
      "source": [
        "#Prediction for image containing dolphin and horse (it should be around [1,1])\n",
        "img_array=cv2.imread(\"/content/drive/MyDrive/tesztdh2.jpg\")#, cv2.IMREAD_GRAYSCALE)\n",
        "new_array=cv2.resize(img_array, (64, 64))\n",
        "new_array1=new_array/255 \n",
        "test_np = np.array(new_array1)\n",
        "test_np_float32=test_np.astype('float32')\n",
        "test_tensor0 = torch.from_numpy(test_np_float32)\n",
        "test_tensor=test_tensor0.reshape(3,64,64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaqjJ8T87WB2"
      },
      "source": [
        "predict_image(test_tensor, model2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFE6NrpwWowb"
      },
      "source": [
        "#Prediction for image containing just dolphin (it should be around [0,1])\n",
        "\n",
        "img_array=cv2.imread(\"/content/drive/MyDrive/tesztd2.jpg\")#, cv2.IMREAD_GRAYSCALE)\n",
        "new_array=cv2.resize(img_array, (64, 64))\n",
        "new_array1=new_array/255 \n",
        "test_np = np.array(new_array1)\n",
        "test_np_float32=test_np.astype('float32')\n",
        "test_tensor0 = torch.from_numpy(test_np_float32)\n",
        "test_tensor=test_tensor0.reshape(3,64,64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2_LbSlgWsec"
      },
      "source": [
        "predict_image(test_tensor, model2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljdSsCP_W5Cq"
      },
      "source": [
        "#Prediction for image containing just horse (it should be around [1,0]) \n",
        "\n",
        "img_array=cv2.imread(\"/content/drive/MyDrive/teszth.jpg\")#, cv2.IMREAD_GRAYSCALE)\n",
        "new_array=cv2.resize(img_array, (64, 64))\n",
        "new_array1=new_array/255 \n",
        "test_np = np.array(new_array1)\n",
        "test_np_float32=test_np.astype('float32')\n",
        "test_tensor0 = torch.from_numpy(test_np_float32)\n",
        "test_tensor=test_tensor0.reshape(3,64,64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2yaKTjJW7OS"
      },
      "source": [
        "predict_image(test_tensor, model2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEw6U4Akgy3B"
      },
      "source": [
        "#-----------------2nd APPROACH USING RESNET 9 (WITHOUT IMAGENET LIBARY AND DATA AUGMENTATION-------------------\n",
        "\n",
        "def F_score(output, label, threshold=0.5, beta=1):\n",
        "    prob = output > threshold\n",
        "    label = label > threshold\n",
        "\n",
        "    TP = (prob & label).sum(1).float()\n",
        "    TN = ((~prob) & (~label)).sum(1).float()\n",
        "    FP = (prob & (~label)).sum(1).float()\n",
        "    FN = ((~prob) & label).sum(1).float()\n",
        "\n",
        "    precision = torch.mean(TP / (TP + FP + 1e-12))\n",
        "    recall = torch.mean(TP / (TP + FN + 1e-12))\n",
        "    F2 = (1 + beta**2) * precision * recall / (beta**2 * precision + recall + 1e-12)\n",
        "    return F2.mean(0)\n",
        "    \n",
        "class ImageClassificationBase(nn.Module):\n",
        "  \n",
        "    def training_step(self, batch):\n",
        "        images, labels = batch \n",
        "        out = self(images)                  # Generate predictions\n",
        "        loss = F.binary_cross_entropy(out, labels)  # Calculate loss\n",
        "        return loss\n",
        "    \n",
        "    def validation_step(self, batch):\n",
        "        images, labels = batch\n",
        "        out = self(images)                    # Generate predictions\n",
        "        loss = F.binary_cross_entropy(out, labels)    # Calculate loss\n",
        "        score = F_score(out, labels)\n",
        "        return {'val_loss': loss.detach(), 'val_acc': score}\n",
        "        \n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
        "        batch_accs = [x['val_acc'] for x in outputs]\n",
        "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
        "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
        "    \n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
        "            epoch, result['train_loss'], result['val_loss'], result['val_acc']))\n",
        "        \n",
        "\n",
        "\n",
        "def conv_block(in_channels, out_channels, pool=False):\n",
        "    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1), \n",
        "              nn.BatchNorm2d(out_channels), \n",
        "              nn.ReLU(inplace=True)]\n",
        "    if pool: layers.append(nn.MaxPool2d(2))\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "# Check out ResNeXT from torch vision:\n",
        "# https://learnopencv.com/multi-label-image-classification-with-pytorch-image-tagging/\n",
        "# NUS-WIDE dataset\n",
        "\n",
        "\n",
        "class ResNet9(ImageClassificationBase):\n",
        "    def __init__(self, in_channels, num_classes):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.conv1 = conv_block(in_channels, 64, pool=True)  #32 x32\n",
        "        self.conv2 = conv_block(64, 128, pool=True)          #16 x 16\n",
        "        self.res1 = nn.Sequential(conv_block(128, 128), conv_block(128, 128))\n",
        "        \n",
        "        self.conv3 = conv_block(128, 256, pool=True) # 8 x 8\n",
        "        self.conv4 = conv_block(256, 512, pool=True) # 4 x 4\n",
        "        self.res2 = nn.Sequential(conv_block(512, 512), conv_block(512, 512))\n",
        "        \n",
        "        self.classifier = nn.Sequential(\n",
        "                                        nn.MaxPool2d(4), \n",
        "                                        nn.Flatten(), \n",
        "                                        #nn.Dropout(0.2),\n",
        "                                        nn.Linear(512, num_classes),\n",
        "                                        nn.Sigmoid())\n",
        "        \n",
        "    def forward(self, xb):\n",
        "        out = self.conv1(xb)\n",
        "        out = self.conv2(out)\n",
        "        out = self.res1(out) + out\n",
        "        out = self.conv3(out)\n",
        "        out = self.conv4(out)\n",
        "        out = self.res2(out) + out\n",
        "        out = self.classifier(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lN1NljVhz5g"
      },
      "source": [
        "#-----if gpu is available\n",
        "\n",
        "def get_default_device():\n",
        "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "    \n",
        "def to_device(data, device):\n",
        "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
        "    if isinstance(data, (list,tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)\n",
        "\n",
        "class DeviceDataLoader():\n",
        "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "        \n",
        "    def __iter__(self):\n",
        "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
        "        for b in self.dl: \n",
        "            yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Number of batches\"\"\"\n",
        "        return len(self.dl)\n",
        "\n",
        "device = get_default_device()\n",
        "\n",
        "model = to_device(ResNet9(3,2), device)\n",
        "train_dl = DeviceDataLoader(train_dl, device)\n",
        "val_dl = DeviceDataLoader(val_dl, device)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9J3gDNKThbDQ"
      },
      "source": [
        "#if GPU is not available\n",
        "\n",
        "model = ResNet9(3, 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdgzBIg8iClW"
      },
      "source": [
        "history = []\n",
        "@torch.no_grad()\n",
        "def evaluate(model, val_loader):\n",
        "    model.eval()\n",
        "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "    return model.validation_epoch_end(outputs)\n",
        "\n",
        "def get_lr(optimizer):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        return param_group['lr']\n",
        "\n",
        "def fit_one_cycle(epochs, max_lr, model, train_loader, val_loader, \n",
        "                  weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD):\n",
        "    torch.cuda.empty_cache()\n",
        "    #history = []\n",
        "    \n",
        "    # Set up cutom optimizer with weight decay\n",
        "    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n",
        "    # Set up one-cycle learning rate scheduler\n",
        "    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, \n",
        "                                               steps_per_epoch=len(train_loader))\n",
        "    #sched = torch.optim.lr_scheduler.StepLR(opt_func, step_size=100, gamma=0.1)\n",
        "    for epoch in range(epochs):\n",
        "        # Training Phase \n",
        "        model.train()\n",
        "        train_losses = []\n",
        "        lrs = []\n",
        "        for batch in train_loader:\n",
        "            loss = model.training_step(batch)\n",
        "            train_losses.append(loss)\n",
        "            loss.backward()\n",
        "            \n",
        "            # Gradient clipping\n",
        "            if grad_clip: \n",
        "                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n",
        "            \n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            # Record & update learning rate\n",
        "            lrs.append(get_lr(optimizer))\n",
        "            sched.step()\n",
        "        \n",
        "        # Validation phase\n",
        "        result = evaluate(model, val_loader)\n",
        "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
        "        result['lrs'] = lrs\n",
        "        model.epoch_end(epoch, result)\n",
        "        history.append(result)\n",
        "    #return history\n",
        "\n",
        "epochs = 5\n",
        "max_lr = 0.01\n",
        "grad_clip = 0.1\n",
        "weight_decay = 1e-4\n",
        "opt_func = torch.optim.Adam\n",
        "\n",
        "\n",
        "fit_one_cycle(epochs, max_lr, model, train_dl, val_dl, \n",
        "                             grad_clip=grad_clip, \n",
        "                             weight_decay=weight_decay, \n",
        "                             opt_func=opt_func)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoRbFoAwipH_"
      },
      "source": [
        "accuracies = [x['val_acc'] for x in history]\n",
        "plt.plot(accuracies)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.title('Accuracy vs. No. of epochs');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmMgsR6gip-X"
      },
      "source": [
        "train_losses = [x.get('train_loss') for x in history]\n",
        "val_losses = [x['val_loss'] for x in history]\n",
        "plt.plot(train_losses)\n",
        "plt.plot(val_losses)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(['Training', 'Validation'])\n",
        "plt.title('Loss vs. No. of epochs');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIvIl99Bihnr"
      },
      "source": [
        "torch.save(model.state_dict(), 'pics.modelparameters')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pI_uYltYibza"
      },
      "source": [
        "model2=ResNet9(3,2)\n",
        "model2.load_state_dict(torch.load('pics.modelparameters'))\n",
        "model2.state_dict\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMwFfLD-iyc_"
      },
      "source": [
        "def predict_image(img, model):\n",
        "    xb = img.unsqueeze(0)\n",
        "    yb = model(xb)\n",
        "    #_, preds  = torch.max(yb, dim=1)\n",
        "    return yb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdqXvBEPi_P-"
      },
      "source": [
        "#Prediction for image containing dolphin and horse (it should be around [1,1])\n",
        "img_array=cv2.imread(\"/content/drive/MyDrive/tesztdh.jpg\")#, cv2.IMREAD_GRAYSCALE)\n",
        "new_array=cv2.resize(img_array, (64, 64))\n",
        "new_array1=new_array/255 \n",
        "test_np = np.array(new_array1)\n",
        "test_np_float32=test_np.astype('float32')\n",
        "test_tensor0 = torch.from_numpy(test_np_float32)\n",
        "test_tensor=test_tensor0.reshape(3,64,64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmtAfoowizlv"
      },
      "source": [
        "predict_image(test_tensor, model2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-Hx9r04jDnQ"
      },
      "source": [
        "#Prediction for image containing just dolphin (it should be around [0,1])\n",
        "\n",
        "img_array=cv2.imread(\"/content/drive/MyDrive/tesztd3.jpg\")#, cv2.IMREAD_GRAYSCALE)\n",
        "new_array=cv2.resize(img_array, (64, 64))\n",
        "new_array1=new_array/255 \n",
        "test_np = np.array(new_array1)\n",
        "test_np_float32=test_np.astype('float32')\n",
        "test_tensor0 = torch.from_numpy(test_np_float32)\n",
        "test_tensor=test_tensor0.reshape(3,64,64)\n",
        "\n",
        "predict_image(test_tensor, model2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wa_bj5yijIjy"
      },
      "source": [
        "#Prediction for image containing just horse (it should be around [1,0]) \n",
        "\n",
        "img_array=cv2.imread(\"/content/drive/MyDrive/teszth2.jpg\")#, cv2.IMREAD_GRAYSCALE)\n",
        "new_array=cv2.resize(img_array, (64, 64))\n",
        "new_array1=new_array/255 \n",
        "test_np = np.array(new_array1)\n",
        "test_np_float32=test_np.astype('float32')\n",
        "test_tensor0 = torch.from_numpy(test_np_float32)\n",
        "test_tensor=test_tensor0.reshape(3,64,64)\n",
        "\n",
        "predict_image(test_tensor, model2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIvuu7f7MJh-"
      },
      "source": [
        "import tensorflow as tf\n",
        "a=tf.Variable([5,6,7],[1,3,4])\n",
        "print(a.rank)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0duBZi3tSZX"
      },
      "source": [
        "-------TENSORFLOW (SEQUENTIAL) DNN MODEL---------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oR1kVJlLR0Nc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "outputId": "b6c950f8-37ce-4b1f-f091-f009eb5ade35"
      },
      "source": [
        "\n",
        "# run the first three division on the top to create the necesary folders\n",
        "\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "\n",
        "\n",
        "datadir=\"/content/train/\" \n",
        "train_categories=['horse/horse_train/', 'dolphin/dolphin_train/', 'dolphin_horse/dolphin_horse_train/']\n",
        "\n",
        "dataset_train=[]\n",
        "def create_train_data():\n",
        "  for category in train_categories:\n",
        "    path_train=os.path.join(datadir, category)\n",
        "    if category==\"horse/horse_train/\":\n",
        "      class_num_train=[1,0]\n",
        "    if category==\"dolphin/dolphin_train/\":\n",
        "      class_num_train=[0,1]\n",
        "    if category==\"dolphin_horse/dolphin_horse_train/\":\n",
        "      class_num_train=[1,1]\n",
        "    for img in os.listdir(path_train):  \n",
        "      try:\n",
        "        img_array=cv2.imread(os.path.join(path_train, img))#, cv2.IMREAD_GRAYSCALE)\n",
        "        new_array=cv2.resize(img_array, (64, 64))  \n",
        "        new_array1=new_array/255 \n",
        "        dataset_train.append([new_array1, class_num_train])\n",
        "      except Exception as e:\n",
        "        print(e)\n",
        "\n",
        "create_train_data()\n",
        "\n",
        "import random\n",
        "random.shuffle(dataset_train)\n",
        "\n",
        "inputs_train=[]\n",
        "targets_train=[]\n",
        "\n",
        "for image, label in dataset_train:\n",
        "  inputs_train.append(image)\n",
        "  targets_train.append(label)\n",
        "\n",
        "#---creating np array from the input images\n",
        "arr_inputs_train = np.array(inputs_train)\n",
        "arr_inputs_float_train=arr_inputs_train.astype('float32')\n",
        "\n",
        "\n",
        "arr_inputs_train_targets = np.array(targets_train)\n",
        "arr_inputs_float_train_targets=arr_inputs_train_targets.astype('float32')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "datadir=\"/content/valid/\" \n",
        "valid_categories=['horse/horse_valid/', 'dolphin/dolphin_valid/', 'dolphin_horse/dolphin_horse_valid/']\n",
        "\n",
        "dataset_valid=[]\n",
        "def create_validation_data():\n",
        "  for category in valid_categories:\n",
        "    path_valid=os.path.join(datadir, category)\n",
        "    if category==\"horse/horse_valid/\":\n",
        "      class_num_valid=[1,0]\n",
        "    if category==\"dolphin/dolphin_valid/\":\n",
        "      class_num_valid=[0,1]\n",
        "    if category==\"dolphin_horse/dolphin_horse_valid/\":\n",
        "      class_num_valid=[1,1]\n",
        "    for img in os.listdir(path_valid):  \n",
        "      try:\n",
        "        img_array=cv2.imread(os.path.join(path_valid, img))#, cv2.IMREAD_GRAYSCALE)\n",
        "        new_array=cv2.resize(img_array, (64, 64))  \n",
        "        new_array1=new_array/255 \n",
        "        dataset_valid.append([new_array1, class_num_valid])\n",
        "      except Exception as e:\n",
        "        print(e)\n",
        "\n",
        "create_validation_data()\n",
        "\n",
        "import random\n",
        "random.shuffle(dataset_valid)\n",
        "\n",
        "inputs_val=[]\n",
        "targets_val=[]\n",
        "\n",
        "for image, label in dataset_valid:\n",
        "  inputs_val.append(image)\n",
        "  targets_val.append(label)\n",
        "\n",
        "#---creating np array from the input images\n",
        "arr_inputs_val = np.array(inputs_val)\n",
        "arr_inputs_float_val=arr_inputs_val.astype('float32')\n",
        "\n",
        "\n",
        "\n",
        "#------TEST DATASET-----------\n",
        "\n",
        "\n",
        "datadir=\"/content/test/\" \n",
        "test_categories=['horse/HorseTest/', 'dolphin/DolphinTest/', 'dolphin_horse/DolphinHorseTest/']\n",
        "\n",
        "dataset_test=[]\n",
        "def create_test_data():\n",
        "  for category in test_categories:\n",
        "    path_test=os.path.join(datadir, category)\n",
        "    if category==\"horse/HorseTest/\":\n",
        "      class_num_test=[1,0]\n",
        "    if category==\"dolphin/DolphinTest/\":\n",
        "      class_num_test=[0,1]\n",
        "    if category==\"dolphin_horse/DolphinHorseTest/\":\n",
        "      class_num_test=[1,1]\n",
        "    for img in os.listdir(path_test):  \n",
        "      try:\n",
        "        img_array=cv2.imread(os.path.join(path_test, img))#, cv2.IMREAD_GRAYSCALE)\n",
        "        new_array=cv2.resize(img_array, (64, 64))  \n",
        "        new_array1=new_array/255 \n",
        "        dataset_test.append([new_array1, class_num_test])\n",
        "      except Exception as e:\n",
        "        print(e)\n",
        "\n",
        "create_test_data()\n",
        "\n",
        "import random\n",
        "random.shuffle(dataset_test)\n",
        "\n",
        "inputs_test=[]\n",
        "targets_test=[]\n",
        "\n",
        "for image, label in dataset_test:\n",
        "  inputs_test.append(image)\n",
        "  targets_test.append(label)\n",
        "\n",
        "#---creating np array from the input images\n",
        "arr_inputs_test = np.array(inputs_test)\n",
        "arr_inputs_float_test=arr_inputs_test.astype('float32')\n",
        "\n",
        "\n",
        "\n",
        "#---------------- NOW YOU CAN RUN THE DNN OR THE CNN MODELS----------\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-fc80f8a0bb03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mcreate_train_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-fc80f8a0bb03>\u001b[0m in \u001b[0;36mcreate_train_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"dolphin_horse/dolphin_horse_train/\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m       \u001b[0mclass_num_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mimg_array\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#, cv2.IMREAD_GRAYSCALE)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/train/horse/horse_train/'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pm5glXI0JDea",
        "outputId": "d2a55f41-7d0d-44df-ba43-7bf5be50c340"
      },
      "source": [
        "print(len(inputs_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "74\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDsGjdkstRwL"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "# 1.) MODEL\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(64,64,3)),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dense(2, activation='sigmoid') \n",
        "    #keras.layers.Sigmoid()\n",
        "\n",
        "    ])\n",
        "\n",
        "# 2.) lOSS, OPTIMIZER, METRICS\n",
        "loss = keras.losses.BinaryCrossentropy(from_logits=False)  #SparseCategoricalCrossentropy as we have single classes(1,2), \n",
        "                                                                    #if it is vector (0,1,0,0....) CategoricalCrossentropy. \n",
        "                                                                    #From_logits=True as we didn't build the softmax into the model\n",
        "optim = keras.optimizers.Adam(lr=0.001)\n",
        "metrics = [\"accuracy\"]\n",
        "\n",
        "# 3.) CONFIGURATION OF THE MODEL\n",
        "\n",
        "model.compile(loss=loss, optimizer=optim, metrics=metrics)\n",
        "\n",
        "# 4.) TRAINING\n",
        "batch_size = 32\n",
        "epochs = 30\n",
        "\n",
        "model.fit(arr_inputs_float_train, arr_inputs_float_train_targets, batch_size=batch_size, epochs=epochs, shuffle=True, verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDumVHnh8OIU"
      },
      "source": [
        "predictions = model(arr_inputs_float_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssqGzT1rJcq9"
      },
      "source": [
        "print(predictions)\n",
        "print(targets_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IOcP_jbJ0In"
      },
      "source": [
        "counter=0\n",
        "for i in range(len(targets_val)):\n",
        "  if targets_val[i][0]==1 and 0.5< predictions[i][0] and targets_val[i][1]==1 and 0.5< predictions[i][1]:  #[1,1]\n",
        "    counter+=1\n",
        "  if targets_val[i][0]==1 and 0.5< predictions[i][0] and targets_val[i][1]==0 and 0.5> predictions[i][1]:   #[1,0]\n",
        "    counter+=1\n",
        "  if targets_val[i][0]==0 and 0.5> predictions[i][0] and targets_val[i][1]==1 and 0.5< predictions[i][1]:    #[0,1]\n",
        "    counter+=1\n",
        "  if targets_val[i][0]==0 and 0.5> predictions[i][0] and targets_val[i][1]==0 and 0.5> predictions[i][1]:    #[0,0]\n",
        "    counter+=1\n",
        "\n",
        "\n",
        "print(counter/len(targets_val))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCAkUEpGcWqT"
      },
      "source": [
        "------- TF_CNN model----------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ypk0Da5cUY0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2522c152-3908-42b9-a395-930a85568c16"
      },
      "source": [
        "\n",
        "\n",
        "modelCNN = keras.models.Sequential()\n",
        "modelCNN.add(layers.Conv2D(32, (3,3), strides=(1,1), padding=\"valid\", activation='relu', input_shape=(64,64,3)))\n",
        "modelCNN.add(layers.MaxPool2D((2,2)))   #32 x 32\n",
        "modelCNN.add(layers.Conv2D(64, 3, activation='relu'))\n",
        "modelCNN.add(layers.MaxPool2D((2,2))) #16 x 16\n",
        "modelCNN.add(layers.Conv2D(128, 3, activation='relu'))\n",
        "modelCNN.add(layers.MaxPool2D((2,2))) #8 x 8\n",
        "modelCNN.add(layers.Conv2D(256, 3, activation='relu'))\n",
        "#modelCNN.add(layers.MaxPool2D((2,2))) #4 x 4\n",
        "modelCNN.add(layers.Conv2D(512, 3, activation='relu'))\n",
        "modelCNN.add(layers.MaxPool2D((2,2))) #4 x 4\n",
        "modelCNN.add(layers.Flatten())\n",
        "modelCNN.add(layers.Dense(1024, activation='relu'))\n",
        "modelCNN.add(layers.Dense(512, activation='relu'))\n",
        "modelCNN.add(layers.Dense(2, activation='sigmoid'))\n",
        "\n",
        "#import sys; sys.exit()\n",
        "\n",
        "# 2.) lOSS, OPTIMIZER, METRICS\n",
        "loss = keras.losses.BinaryCrossentropy(from_logits=False)  #SparseCategoricalCrossentropy as we have single classes(1,2), \n",
        "                                                                    #if it is vector (0,1,0,0....) CategoricalCrossentropy. \n",
        "                                                                    #From_logits=True as we didn't build the softmax into the model\n",
        "optim = keras.optimizers.Adam(lr=0.001)\n",
        "metrics = [\"accuracy\"]\n",
        "\n",
        "# 3.) CONFIGURATION OF THE MODEL\n",
        "\n",
        "modelCNN.compile(loss=loss, optimizer=optim, metrics=metrics)\n",
        "\n",
        "# 4.) TRAINING\n",
        "batch_size = 32\n",
        "epochs = 30\n",
        "\n",
        "history=modelCNN.fit(arr_inputs_float_train, arr_inputs_float_train_targets, batch_size=batch_size, epochs=epochs, shuffle=True, verbose=2, validation_split = 0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "12/12 - 1s - loss: 0.6556 - accuracy: 0.6558 - val_loss: 0.4733 - val_accuracy: 0.7957\n",
            "Epoch 2/30\n",
            "12/12 - 0s - loss: 0.4154 - accuracy: 0.8157 - val_loss: 0.4458 - val_accuracy: 0.7634\n",
            "Epoch 3/30\n",
            "12/12 - 0s - loss: 0.3690 - accuracy: 0.8347 - val_loss: 0.3849 - val_accuracy: 0.7957\n",
            "Epoch 4/30\n",
            "12/12 - 0s - loss: 0.3459 - accuracy: 0.8564 - val_loss: 0.3464 - val_accuracy: 0.8387\n",
            "Epoch 5/30\n",
            "12/12 - 0s - loss: 0.3497 - accuracy: 0.8509 - val_loss: 0.3563 - val_accuracy: 0.8495\n",
            "Epoch 6/30\n",
            "12/12 - 0s - loss: 0.2945 - accuracy: 0.8672 - val_loss: 0.3400 - val_accuracy: 0.8495\n",
            "Epoch 7/30\n",
            "12/12 - 0s - loss: 0.2724 - accuracy: 0.8645 - val_loss: 0.3516 - val_accuracy: 0.8280\n",
            "Epoch 8/30\n",
            "12/12 - 0s - loss: 0.3250 - accuracy: 0.8564 - val_loss: 0.3591 - val_accuracy: 0.8495\n",
            "Epoch 9/30\n",
            "12/12 - 0s - loss: 0.2969 - accuracy: 0.8428 - val_loss: 0.3397 - val_accuracy: 0.8495\n",
            "Epoch 10/30\n",
            "12/12 - 0s - loss: 0.2343 - accuracy: 0.8780 - val_loss: 0.3025 - val_accuracy: 0.8710\n",
            "Epoch 11/30\n",
            "12/12 - 0s - loss: 0.2042 - accuracy: 0.8808 - val_loss: 0.2777 - val_accuracy: 0.8710\n",
            "Epoch 12/30\n",
            "12/12 - 0s - loss: 0.1847 - accuracy: 0.8862 - val_loss: 0.2774 - val_accuracy: 0.8710\n",
            "Epoch 13/30\n",
            "12/12 - 0s - loss: 0.1659 - accuracy: 0.8970 - val_loss: 0.3296 - val_accuracy: 0.8495\n",
            "Epoch 14/30\n",
            "12/12 - 0s - loss: 0.1855 - accuracy: 0.9051 - val_loss: 0.2272 - val_accuracy: 0.8925\n",
            "Epoch 15/30\n",
            "12/12 - 0s - loss: 0.1642 - accuracy: 0.8970 - val_loss: 0.2913 - val_accuracy: 0.8925\n",
            "Epoch 16/30\n",
            "12/12 - 0s - loss: 0.1833 - accuracy: 0.8889 - val_loss: 0.4190 - val_accuracy: 0.7957\n",
            "Epoch 17/30\n",
            "12/12 - 0s - loss: 0.1292 - accuracy: 0.9106 - val_loss: 0.2718 - val_accuracy: 0.8387\n",
            "Epoch 18/30\n",
            "12/12 - 0s - loss: 0.1194 - accuracy: 0.9214 - val_loss: 0.3300 - val_accuracy: 0.8817\n",
            "Epoch 19/30\n",
            "12/12 - 0s - loss: 0.1250 - accuracy: 0.9322 - val_loss: 0.5196 - val_accuracy: 0.8172\n",
            "Epoch 20/30\n",
            "12/12 - 0s - loss: 0.1190 - accuracy: 0.9268 - val_loss: 0.3971 - val_accuracy: 0.8925\n",
            "Epoch 21/30\n",
            "12/12 - 0s - loss: 0.0796 - accuracy: 0.9295 - val_loss: 0.3507 - val_accuracy: 0.8602\n",
            "Epoch 22/30\n",
            "12/12 - 0s - loss: 0.0625 - accuracy: 0.8997 - val_loss: 0.3957 - val_accuracy: 0.8602\n",
            "Epoch 23/30\n",
            "12/12 - 0s - loss: 0.0660 - accuracy: 0.8943 - val_loss: 0.3752 - val_accuracy: 0.8710\n",
            "Epoch 24/30\n",
            "12/12 - 0s - loss: 0.0737 - accuracy: 0.9133 - val_loss: 0.3737 - val_accuracy: 0.8710\n",
            "Epoch 25/30\n",
            "12/12 - 0s - loss: 0.0528 - accuracy: 0.9106 - val_loss: 0.4692 - val_accuracy: 0.8065\n",
            "Epoch 26/30\n",
            "12/12 - 0s - loss: 0.0995 - accuracy: 0.8997 - val_loss: 0.2988 - val_accuracy: 0.8817\n",
            "Epoch 27/30\n",
            "12/12 - 0s - loss: 0.0547 - accuracy: 0.8997 - val_loss: 0.3106 - val_accuracy: 0.8602\n",
            "Epoch 28/30\n",
            "12/12 - 0s - loss: 0.0253 - accuracy: 0.9051 - val_loss: 0.3434 - val_accuracy: 0.8925\n",
            "Epoch 29/30\n",
            "12/12 - 0s - loss: 0.0206 - accuracy: 0.9295 - val_loss: 0.4309 - val_accuracy: 0.8710\n",
            "Epoch 30/30\n",
            "12/12 - 0s - loss: 0.0145 - accuracy: 0.8943 - val_loss: 0.4075 - val_accuracy: 0.9032\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJW6a4lHiOUT"
      },
      "source": [
        "predictions = modelCNN(arr_inputs_float_val)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEBkLNc2Qv5q",
        "outputId": "d4763d08-bdad-4190-94b9-c303e605f39c"
      },
      "source": [
        "counter=0\n",
        "for i in range(len(targets_val)):\n",
        "  if targets_val[i][0]==1 and 0.5< predictions[i][0] and targets_val[i][1]==1 and 0.5< predictions[i][1]:  #[1,1]\n",
        "    counter+=1\n",
        "  if targets_val[i][0]==1 and 0.5< predictions[i][0] and targets_val[i][1]==0 and 0.5> predictions[i][1]:   #[1,0]\n",
        "    counter+=1\n",
        "  if targets_val[i][0]==0 and 0.5> predictions[i][0] and targets_val[i][1]==1 and 0.5< predictions[i][1]:    #[0,1]\n",
        "    counter+=1\n",
        "  if targets_val[i][0]==0 and 0.5> predictions[i][0] and targets_val[i][1]==0 and 0.5> predictions[i][1]:    #[0,0]\n",
        "    counter+=1\n",
        "\n",
        "\n",
        "print(counter/len(targets_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9207920792079208\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmgX6HhZH50B"
      },
      "source": [
        "\n",
        "plt.plot(history.history['loss'], label='loss')\n",
        "plt.plot(history.history['val_loss'], label='val_loss')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7H5iYcHxYOAv"
      },
      "source": [
        "modelCNN.save(\"nn_Horse_Dolphin.h5\")  \n",
        "\n",
        "new_model = keras.models.load_model(\"nn_Horse_Dolphin.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-O5o2m9SXa-",
        "outputId": "80e91d88-dcf3-430b-9755-9557b48420ac"
      },
      "source": [
        "predictions = new_model(arr_inputs_float_val)\n",
        "\n",
        "counter=0\n",
        "for i in range(len(targets_val)):\n",
        "  if targets_val[i][0]==1 and 0.5< predictions[i][0] and targets_val[i][1]==1 and 0.5< predictions[i][1]:  #[1,1]\n",
        "    counter+=1\n",
        "  if targets_val[i][0]==1 and 0.5< predictions[i][0] and targets_val[i][1]==0 and 0.5> predictions[i][1]:   #[1,0]\n",
        "    counter+=1\n",
        "  if targets_val[i][0]==0 and 0.5> predictions[i][0] and targets_val[i][1]==1 and 0.5< predictions[i][1]:    #[0,1]\n",
        "    counter+=1\n",
        "  if targets_val[i][0]==0 and 0.5> predictions[i][0] and targets_val[i][1]==0 and 0.5> predictions[i][1]:    #[0,0]\n",
        "    counter+=1\n",
        "\n",
        "\n",
        "print(counter/len(targets_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9207920792079208\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYCinv_fIGCs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39cd88a8-a3fa-4e21-879b-55cb9849c1d9"
      },
      "source": [
        "#Check the model on the test dataset\n",
        "\n",
        "predictions=new_model(arr_inputs_float_test)\n",
        "\n",
        "counter=0\n",
        "for i in range(len(targets_test)):\n",
        "  if targets_test[i][0]==1 and 0.5< predictions[i][0] and targets_test[i][1]==1 and 0.5< predictions[i][1]:  #[1,1]\n",
        "    counter+=1\n",
        "  if targets_test[i][0]==1 and 0.5< predictions[i][0] and targets_test[i][1]==0 and 0.5> predictions[i][1]:   #[1,0]\n",
        "    counter+=1\n",
        "  if targets_test[i][0]==0 and 0.5> predictions[i][0] and targets_test[i][1]==1 and 0.5< predictions[i][1]:    #[0,1]\n",
        "    counter+=1\n",
        "  if targets_test[i][0]==0 and 0.5> predictions[i][0] and targets_test[i][1]==0 and 0.5> predictions[i][1]:    #[0,0]\n",
        "    counter+=1\n",
        "\n",
        "\n",
        "print(counter/len(targets_test))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9054054054054054\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ny4_cJHwKymK"
      },
      "source": [
        "a=predictions.numpy()\n",
        "torch_predictions=torch.tensor(a, dtype=torch.float32)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UszoYU9AB1Po",
        "outputId": "61ccdf6e-b409-42a6-b579-7e1f0b83355c"
      },
      "source": [
        "arr_inputs_test = np.array(targets_test)\n",
        "arr_inputs_float_targetstest=arr_inputs_test.astype('float32')\n",
        "\n",
        "def F_score(output, label, threshold=0.5, beta=1):\n",
        "    prob = output > threshold\n",
        "    label = label > threshold\n",
        "\n",
        "    TP = (prob & label).sum(1).float()\n",
        "    TN = ((~prob) & (~label)).sum(1).float()\n",
        "    FP = (prob & (~label)).sum(1).float()\n",
        "    FN = ((~prob) & label).sum(1).float()\n",
        "\n",
        "    precision = torch.mean(TP / (TP + FP + 1e-12))\n",
        "    recall = torch.mean(TP / (TP + FN + 1e-12))\n",
        "    F2 = (1 + beta**2) * precision * recall / (beta**2 * precision + recall + 1e-12)\n",
        "\n",
        "    # F2 = 2* precision * recall / (precision + recall)\n",
        "\n",
        "    return F2.mean(0)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "score = F_score(torch_predictions, arr_inputs_float_targetstest)\n",
        "print(score)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.9459)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WLXMb_fIdY9",
        "outputId": "ccc0f9a6-9a12-42df-e7ec-98ac8f9c2c1f"
      },
      "source": [
        "len(arr_inputs_float_test)\n",
        "#len(arr_inputs_float_targetstest)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "101"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    }
  ]
}